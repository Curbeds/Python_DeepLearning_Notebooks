
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_size = 90\n",
    "context = 5\n",
    "\n",
    "input_x = tf.placeholder(dtype = tf.float32, shape = [None, feat_size*(2*context +1)])\n",
    "output_y = tf.placeholder(dtype = tf.float32, shape = [None, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#hidden layer 1\n",
    "\n",
    "hidden_1 = 512\n",
    "hidden_1_weights = tf.get_variable( \"hidden_1_weights\",\n",
    "                                  shape = [ feat_size*(2*context +1), hidden_1],\n",
    "                                  dtype = tf.float32,\n",
    "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_1_bias = tf.get_variable( \"hidden_1_bias\",\n",
    "                                    shape = [hidden_1],\n",
    "                                    dtype = tf.float32,\n",
    "                                   initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_1_dnn = tf.matmul( input_x, hidden_1_weights) + hidden_1_bias\n",
    "hidden_1_out = tf.nn.relu(hidden_1_dnn)\n",
    "print(hidden_1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#hidden layer 2\n",
    "\n",
    "hidden_2 = 512\n",
    "hidden_2_weights = tf.get_variable( \"hidden_2_weights\",\n",
    "                                  shape = [ hidden_1, hidden_2],\n",
    "                                  dtype = tf.float32,\n",
    "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_2_bias = tf.get_variable( \"hidden_2_bias\",\n",
    "                                    shape = [hidden_2],\n",
    "                                    dtype = tf.float32,\n",
    "                                   initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_2_dnn = tf.matmul( hidden_1_out, hidden_2_weights) + hidden_2_bias\n",
    "hidden_2_out = tf.nn.relu(hidden_2_dnn)\n",
    "print(hidden_2_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#hidden layer 3\n",
    "\n",
    "hidden_3 = 512\n",
    "hidden_3_weights = tf.get_variable( \"hidden_3_weights\",\n",
    "                                  shape = [ hidden_2, hidden_3],\n",
    "                                  dtype = tf.float32,\n",
    "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_3_bias = tf.get_variable( \"hidden_3_bias\",\n",
    "                                    shape = [hidden_3],\n",
    "                                    dtype = tf.float32,\n",
    "                                 initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_3_dnn = tf.matmul( hidden_2_out, hidden_3_weights) + hidden_3_bias\n",
    "hidden_3_out = tf.nn.relu(hidden_3_dnn)\n",
    "print(hidden_3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_3:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#hidden layer 4\n",
    "\n",
    "hidden_4 = 256\n",
    "hidden_4_weights = tf.get_variable( \"hidden_4_weights\",\n",
    "                                  shape = [ hidden_3, hidden_4],\n",
    "                                  dtype = tf.float32,\n",
    "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_4_bias = tf.get_variable( \"hidden_4_bias\",\n",
    "                                    shape = [hidden_4],\n",
    "                                    dtype = tf.float32,\n",
    "                                   initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_4_dnn = tf.matmul( hidden_3_out, hidden_4_weights) + hidden_4_bias\n",
    "hidden_4_out = tf.nn.relu(hidden_4_dnn)\n",
    "print(hidden_4_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_4:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#hidden layer 5\n",
    "\n",
    "hidden_5 = 256\n",
    "hidden_5_weights = tf.get_variable( \"hidden_5_weights\",\n",
    "                                  shape = [ hidden_4, hidden_5],\n",
    "                                  dtype = tf.float32,\n",
    "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_5_bias = tf.get_variable( \"hidden_5_bias\",\n",
    "                                    shape = [hidden_5],\n",
    "                                    dtype = tf.float32,\n",
    "                                   initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "hidden_5_dnn = tf.matmul( hidden_4_out, hidden_5_weights) + hidden_5_bias\n",
    "hidden_5_out = tf.nn.relu(hidden_5_dnn)\n",
    "print(hidden_5_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#output layer \n",
    "\n",
    "output_dim = 2\n",
    "output_layer_weights = tf.get_variable(\"output_layer_weights\",\n",
    "                                      shape = [hidden_5 ,output_dim],\n",
    "                                      dtype = tf.float32,\n",
    "                                      initializer = tf.contrib.layers.xavier_initializer())\n",
    "output_layer_bias = tf.get_variable(\"output_layer_bias\",\n",
    "                                   shape = [output_dim],\n",
    "                                   dtype = tf.float32,\n",
    "                                   initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "output_layer_sum = tf.matmul(hidden_5_out, output_layer_weights) + output_layer_bias\n",
    "final_output = tf.nn.softmax(output_layer_sum)\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses and optimizers\n",
    "\n",
    "cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(labels = output_y, logits = output_layer_sum))\n",
    "optimizer = tf.train.AdamOptimizer(1e-2)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "correct_predictions = tf.equal(tf.argmax(final_output,1),tf.argmax(output_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing tensors\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep = None)\n",
    "\n",
    "features_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\contextData_90D'\n",
    "dev_features_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\devcontextData_90D'\n",
    "#eval_features_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\evalcontextData'\n",
    "model_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\Models_90D'\n",
    "\n",
    "dev_sp_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\Dev_sp_90D'\n",
    "#eval_sp_path = 'C:\\\\Users\\\\HIMANSHU\\\\Desktop\\\\Aditya\\\\ASVspoof2017_CMPOC_CMVN\\\\Eval_sp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eer(scores_true, scores_false):\n",
    "    \n",
    "    \"\"\" Calculate EER\n",
    "        Args:\n",
    "            scores_true: A score list of positive samples\n",
    "            scores_false: A score list of negative samples\n",
    "        Return:\n",
    "            (EER, threshold)\n",
    "        Note:\n",
    "            Here, the threshold is set, and if the score is higher than or equal to the threshold,\n",
    "            the decision is passed, and the decision is rejected as below.\n",
    "    \"\"\"\n",
    "    min1 = min(scores_true)\n",
    "    min2 = min(scores_false)\n",
    "    low = min(min1, min2)\n",
    "    max1 = max(scores_true)\n",
    "    max2 = max(scores_false)\n",
    "    high = max(max1, max2)\n",
    "    FAR = -55\n",
    "    FRR = -55\n",
    "    mid = -100\n",
    "    # Bisection find threshold\n",
    "    while True:\n",
    "        bef_FAR = FAR \n",
    "        bef_FRR = FRR\n",
    "        bef_mid = mid\n",
    "        mid = (high + low) / 2\n",
    "        FRR = sum([1 for s in scores_true if s < mid]) / len(scores_true)\n",
    "        FAR = sum([1 for s in scores_false if s >= mid]) / len(scores_false)\n",
    "        #print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "\n",
    "        if abs(FRR - FAR) < 1e-7:\n",
    "            print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "            break\n",
    "\n",
    "        if FRR < FAR:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "            \n",
    "        if bef_FAR == FAR :\n",
    "            if bef_FRR == FRR :\n",
    "                if bef_mid == mid :\n",
    "                    print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "                    break\n",
    "\n",
    "    EER  =  FRR\n",
    "    return EER, (high + low) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "def get_EER(test_path, index, sp_path ):\n",
    "    scores = []\n",
    "    development_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    #test_path = \"C:\\\\Users\\\\project1\\\\Desktop\\\\Siva\\\\HT_IFCC_hemlata\\\\CNN_input_testing_dev\"\n",
    "    indexs = (len(list(os.listdir(test_path))))//2\n",
    "    \n",
    "    for folders in range(1, indexs+1):\n",