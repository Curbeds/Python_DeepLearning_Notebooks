{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN and Out variables for data \n",
    "dimension = 120\n",
    "fps = 100 #frames per second\n",
    "filters = 128\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, dimension, fps])  #Inputs\n",
    "y = tf.placeholder(tf.float32, [None, 2])   #Labels\n",
    "keep_prob = tf.placeholder(dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 120, 100, 1), dtype=float32)\n",
      "Tensor(\"Sigmoid:0\", shape=(?, 1, 98, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#convolution Layer - 1 \n",
    "weights_conv1 = tf.get_variable( \"weights_conv1\", shape = [dimension, 3, 1, filters], \n",
    "                                  initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "bias_conv1 = tf.get_variable( \"bias_conv1\", shape = [filters],\n",
    "                             initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "input_x = tf.reshape(x, [-1, dimension, fps, 1])\n",
    "print(input_x)\n",
    "\n",
    "#output\n",
    "conv1 = tf.nn.conv2d( input_x, weights_conv1, strides=[1, 1, 1, 1], padding='VALID') \n",
    "conv1_out = tf.nn.sigmoid( conv1 + bias_conv1 )\n",
    "conv1_drop = tf.nn.dropout(conv1_out, keep_prob)\n",
    "print(conv1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_1/mul:0\", shape=(?, 1, 96, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#convolution layer - 2\n",
    "\n",
    "weights_conv2 = tf.get_variable( \"weights_conv2\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv2 = tf.get_variable(\"bias_conv2\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "#output\n",
    "conv2 = tf.nn.conv2d( conv1_drop, weights_conv2, strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "conv2_out = tf.nn.sigmoid( conv2 + bias_conv2)\n",
    "conv2_drop = tf.nn.dropout(conv2_out, keep_prob)\n",
    "print(conv2_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_2/mul:0\", shape=(?, 1, 94, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#convolution layer - 3\n",
    "\n",
    "weights_conv3 = tf.get_variable( \"weights_conv3\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv3 = tf.get_variable(\"bias_conv3\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "#output\n",
    "conv3 = tf.nn.conv2d( conv2_drop, weights_conv3, strides = [1, 1, 1, 1], padding ='VALID')\n",
    "conv3_out = tf.nn.sigmoid( conv3 + bias_conv3)\n",
    "conv3_drop = tf.nn.dropout(conv3_out, keep_prob)\n",
    "print(conv3_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_3/mul:0\", shape=(?, 1, 47, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Max pooling layer\n",
    "\n",
    "weights_conv4 = tf.get_variable( \"weights_conv4\", shape = [ 1, 2, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv4 = tf.get_variable(\"bias_conv4\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv4 = tf.nn.conv2d( conv3_drop, weights_conv4, strides = [1, 2, 2, 1], padding = \"VALID\")\n",
    "conv4_out = tf.nn.sigmoid( conv4 + bias_conv4 )\n",
    "conv4_drop = tf.nn.dropout(conv4_out, keep_prob)\n",
    "pool_out = conv4_drop\n",
    "print(pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_4/mul:0' shape=(?, 1, 45, 128) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv5 = tf.get_variable( \"weights_conv5\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv5 = tf.get_variable(\"bias_conv5\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv5 = tf.nn.conv2d( pool_out, weights_conv5, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv5_out = tf.nn.sigmoid( conv5 + bias_conv5 )\n",
    "conv5_drop = tf.nn.dropout(conv5_out, keep_prob)\n",
    "conv5_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_5/mul:0' shape=(?, 1, 43, 128) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv6 = tf.get_variable( \"weights_conv6\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv6 = tf.get_variable(\"bias_conv6\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv6 = tf.nn.conv2d( conv5_drop, weights_conv6, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv6_out = tf.nn.sigmoid( conv6 + bias_conv6 )\n",
    "conv6_drop = tf.nn.dropout(conv6_out, keep_prob)\n",
    "conv6_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_6/mul:0' shape=(?, 1, 41, 128) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv7 = tf.get_variable( \"weights_conv7\", shape = [ 1, 3, filters, filters],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv7 = tf.get_variable(\"bias_conv7\", shape = [filters],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv7 = tf.nn.conv2d( conv6_drop, weights_conv7, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv7_out = tf.nn.sigmoid( conv7 + bias_conv7 )\n",
    "conv7_drop = tf.nn.dropout( conv7_out, keep_prob)\n",
    "conv7_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout_7/mul:0' shape=(?, 1, 41, 2) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv8 = tf.get_variable( \"weights_conv8\", shape = [ 1, 1, filters, 2],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_conv8 = tf.get_variable(\"bias_conv8\", shape = [2],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv8 = tf.nn.conv2d( conv7_drop, weights_conv8, strides = [1, 1, 1, 1], padding = \"VALID\")\n",
    "conv8_out = tf.nn.sigmoid( conv8 + bias_conv8 )\n",
    "conv8_drop = tf.nn.dropout( conv8_out, keep_prob)\n",
    "conv8_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid_8:0' shape=(?, 1, 1, 2) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final output layer\n",
    "weights_final = tf.get_variable( \"weights_final\", shape = [ 1, 41, 2, 2],\n",
    "                               initializer = tf.contrib.layers.xavier_initializer())\n",
    "bias_final = tf.get_variable(\"bias_final\", shape = [2],\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "conv_final = tf.nn.conv2d( conv8_drop, weights_final, strides = [1, 41, 1, 1], padding = \"VALID\")\n",
    "conv_final = tf.nn.sigmoid( conv_final + bias_final )\n",
    "conv_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = tf.reshape(conv_final, shape = [-1, 2])\n",
    "\n",
    "output = tf.nn.softmax(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses and optimizers\n",
    "\n",
    "cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = final_output))\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "correct_predictions = tf.equal( tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean( tf.cast( correct_predictions, tf.float32 ))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# matric for testing on development \n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "test_path =\"E:\\\\Hemlata_CSL\\\\MFCC\\\\CNN_input_dev_data\"\n",
    "\n",
    "for folders in os.listdir(test_path):\n",
    "    print(folders)\n",
    "    features = np.load(os.path.join(test_path, folders, \"feature_image.npy\"))\n",
    "    print(features.shape)\n",
    "    labels = np.load(os.path.join(test_path, folders, \"label_image.npy\"))\n",
    "    for i in range(labels.shape[0]):\n",
    "        test_features.append(features[i])\n",
    "        test_labels.append(labels[i])\n",
    "    \n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing tensors using sessoion\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "features_path = \"/home/speechlab/ASV/siva/IFCC/overlap_data_100_50\"\n",
    "development_path = \"/home/speechlab/ASV/siva/IFCC/dev_overlap_data_100_50\"\n",
    "#evaluation_path = \"E:\\\\Hemlata_CSL\\\\MFCC\\\\CNN_input_testing_eval\"\n",
    "model_path = \"/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/Models/\"\n",
    "    \n",
    "dev_sp_path =\"/home/speechlab/ASV/siva/IFCC/100_50_full_conv_3k_sig/dev\"\n",
    "#eva_sp_path = \"E:\\\\Hemlata_CSL\\\\MFCC\\\\4_conv\\\\eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eer(scores_true, scores_false):\n",
    "    \n",
    "    \"\"\" Calculate EER\n",
    "        Args:\n",
    "            scores_true: A score list of positive samples\n",
    "            scores_false: A score list of negative samples\n",
    "        Return:\n",
    "            (EER, threshold)\n",
    "        Note:\n",
    "            Here, the threshold is set, and if the sc