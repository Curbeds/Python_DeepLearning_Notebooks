
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = 120\n",
    "fps = 100\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None, feat_dim, fps])\n",
    "y = tf.placeholder( tf.float32, shape = [None, 2])\n",
    "\n",
    "input_x = tf.reshape( x, shape = [-1, feat_dim, fps, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d( input_x, \n",
    "                                filters = 32,\n",
    "                                kernel_size = 9,\n",
    "                                padding = 'VALID',\n",
    "                                activation = tf.nn.relu,\n",
    "                                name = \"conv1_caps\")\n",
    "\n",
    "# conv2 = tf.layers.conv2d( conv1, \n",
    "#                                 filters = 32,\n",
    "#                                 kernel_size = 9,\n",
    "#                                 padding = 'VALID',\n",
    "#                                 activation = tf.nn.relu,\n",
    "#                                 name = \"conv2_caps\")\n",
    "\n",
    "conv_out = tf.layers.conv2d( conv1, \n",
    "                                filters = 32,\n",
    "                                kernel_size = 9,\n",
    "                                strides = 2,\n",
    "                                padding = \"VALID\",\n",
    "                                activation = tf.nn.relu,\n",
    "                                name = \"conv3_caps\")\n",
    "\n",
    "# conv4 = tf.layers.conv2d( conv3, \n",
    "#                                 filters = 64,\n",
    "#                                 kernel_size = 9,\n",
    "#                                 strides = 2,\n",
    "#                                 padding = \"VALID\",\n",
    "#                                 activation = tf.nn.relu,\n",
    "#                                 name = \"conv4_caps\")\n",
    "# print(conv3)\n",
    "epsilon = 1e-7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3_caps/Relu:0' shape=(?, 52, 42, 32) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector, axis = -2, keep_dims = True):\n",
    "    norm = tf.reduce_sum( tf.square(vector), axis, keep_dims )\n",
    "    scalar_factor = norm / (1. + norm)\n",
    "    unit_vector = vector / tf.sqrt( norm + epsilon)\n",
    "    return scalar_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primary capsules\n",
    "vector_dim = 8\n",
    "total_capsules = int( conv_out.shape[1]*conv_out.shape[2]*conv_out.shape[3] //vector_dim)  #6 * 6 * 32\n",
    "raw_capsules = tf.reshape( conv_out, shape = [-1, total_capsules, vector_dim ])\n",
    "primary_capsules = squash( raw_capsules, -1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul:0\", shape=(?, 8736, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(primary_capsules)\n",
    "batch_size = tf.shape(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_2:0\", shape=(?, 512, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sel_cap_dim = 512\n",
    "\n",
    "fully_con_weights = tf.Variable( tf.random_normal( shape = [1, total_capsules, sel_cap_dim ], \n",
    "                                                 stddev = 0.1,\n",
    "                                                 dtype = tf.float32))\n",
    "\n",
    "fully_con_weights_tile = tf.tile( fully_con_weights, [batch_size, 1, 1])\n",
    "\n",
    "selected_capusles = tf.matmul(primary_capsules, fully_con_weights_tile, transpose_a = True)\n",
    "selected_capusles = tf.reshape(selected_capusles, shape = [-1, sel_cap_dim, vector_dim])\n",
    "print(selected_capusles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'tranf_weig_tiled:0' shape=(?, 512, 2, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vector = 16\n",
    "output_labels = 2\n",
    "                                                            # [ 1, 1152, 10, 16, 8]\n",
    "transfer_weights = tf.Variable( \n",
    "                        tf.random_normal( shape = [1, sel_cap_dim, output_labels, output_vector, vector_dim],\n",
    "                                            stddev = 0.1, \n",
    "                                            dtype = tf.float32), \n",
    "                        name = \"transfer_weights\")\n",
    "\n",
    "batch_size = tf.shape(x)[0]\n",
    "tranf_weig_tiled = tf.tile( transfer_weights, [ batch_size, 1, 1, 1, 1], name =\"tranf_weig_tiled\" )\n",
    "tranf_weig_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_caps_reshape = tf.reshape( selected_capusles, \n",
    "                              shape = [batch_size, sel_cap_dim, 1, vector_dim, 1],\n",
    "                              name = \"pri_caps_reshape\")\n",
    "sel_caps_tiled = tf.tile( sel_caps_reshape,\n",
    "                         [1, 1, output_labels, 1, 1],\n",
    "                         name = \"pri_caps_tiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'raw_predictions:0' shape=(?, 512, 2, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_caps_pred_vect = tf.matmul( tranf_weig_tiled, sel_caps_tiled,\n",
    "                              name = \"raw_predictions\")\n",
    "all_caps_pred_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-9c31ae7ee038>:8: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "# dynamic routing round-1\n",
    "b = tf.zeros( shape = [1, sel_cap_dim, output_labels, 1, 1], \n",
    "             dtype = tf.float32,\n",
    "             name = \"b\")\n",
    "\n",
    "coup_coeff = tf.nn.softmax( b, \n",
    "                           dim = 2,\n",
    "                           name = \"coup_coeff\")\n",
    "\n",
    "weighted_all_cap_pred = tf.multiply( coup_coeff, all_caps_pred_vect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weighted_all_cap_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-641e5fa8c448>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#sum over all 1152 capsules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m weighted_pred_vec_r1 = tf.reduce_sum( weighted_all_cap_pred, \n\u001b[0m\u001b[0;32m      3\u001b[0m                              \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                              \u001b[0mkeepdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              name = \"weighted_pred_vec_r1\")\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weighted_all_cap_pred' is not defined"
     ]
    }
   ],
   "source": [
    "#sum over all 1152 capsules\n",
    "weighted_pred_vec_r1 = tf.reduce_sum( weighted_all_cap_pred, \n",
    "                             axis = 1, \n",
    "                             keepdims = True,\n",
    "                             name = \"weighted_pred_vec_r1\")\n",
    "\n",