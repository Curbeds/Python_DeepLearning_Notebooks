
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = 120\n",
    "fps = 100\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None, feat_dim, fps])\n",
    "y = tf.placeholder( tf.float32, shape = [None, 2])\n",
    "\n",
    "input_x = tf.reshape( x, shape = [-1, feat_dim, fps, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d( input_x, \n",
    "                                filters = 32,\n",
    "                                kernel_size = 9,\n",
    "                                padding = 'VALID',\n",
    "                                activation = tf.nn.relu,\n",
    "                                name = \"conv1_caps\")\n",
    "\n",
    "# conv2 = tf.layers.conv2d( conv1, \n",
    "#                                 filters = 32,\n",
    "#                                 kernel_size = 9,\n",
    "#                                 padding = 'VALID',\n",
    "#                                 activation = tf.nn.relu,\n",
    "#                                 name = \"conv2_caps\")\n",
    "\n",
    "conv_out = tf.layers.conv2d( conv1, \n",
    "                                filters = 32,\n",
    "                                kernel_size = 9,\n",
    "                                strides = 2,\n",
    "                                padding = \"VALID\",\n",
    "                                activation = tf.nn.relu,\n",
    "                                name = \"conv3_caps\")\n",
    "\n",
    "# conv4 = tf.layers.conv2d( conv3, \n",
    "#                                 filters = 64,\n",
    "#                                 kernel_size = 9,\n",
    "#                                 strides = 2,\n",
    "#                                 padding = \"VALID\",\n",
    "#                                 activation = tf.nn.relu,\n",
    "#                                 name = \"conv4_caps\")\n",
    "# print(conv3)\n",
    "epsilon = 1e-7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3_caps/Relu:0' shape=(?, 52, 42, 32) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector, axis = -2, keep_dims = True):\n",
    "    norm = tf.reduce_sum( tf.square(vector), axis, keep_dims )\n",
    "    scalar_factor = norm / (1. + norm)\n",
    "    unit_vector = vector / tf.sqrt( norm + epsilon)\n",
    "    return scalar_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primary capsules\n",
    "vector_dim = 8\n",
    "total_capsules = int( conv_out.shape[1]*conv_out.shape[2]*conv_out.shape[3] //vector_dim)  #6 * 6 * 32\n",
    "raw_capsules = tf.reshape( conv_out, shape = [-1, total_capsules, vector_dim ])\n",
    "primary_capsules = squash( raw_capsules, -1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul:0\", shape=(?, 8736, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(primary_capsules)\n",
    "batch_size = tf.shape(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_2:0\", shape=(?, 512, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sel_cap_dim = 512\n",
    "\n",
    "fully_con_weights = tf.Variable( tf.random_normal( shape = [1, total_capsules, sel_cap_dim ], \n",
    "                                                 stddev = 0.1,\n",
    "                                                 dtype = tf.float32))\n",
    "\n",
    "fully_con_weights_tile = tf.tile( fully_con_weights, [batch_size, 1, 1])\n",
    "\n",
    "selected_capusles = tf.matmul(primary_capsules, fully_con_weights_tile, transpose_a = True)\n",
    "selected_capusles = tf.reshape(selected_capusles, shape = [-1, sel_cap_dim, vector_dim])\n",
    "print(selected_capusles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'tranf_weig_tiled:0' shape=(?, 512, 2, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vector = 16\n",
    "output_labels = 2\n",
    "                                                            # [ 1, 1152, 10, 16, 8]\n",
    "transfer_weights = tf.Variable( \n",
    "                        tf.random_normal( shape = [1, sel_cap_dim, output_labels, output_vector, vector_dim],\n",
    "                                            stddev = 0.1, \n",
    "                                            dtype = tf.float32), \n",
    "                        name = \"transfer_weights\")\n",
    "\n",
    "batch_size = tf.shape(x)[0]\n",
    "tranf_weig_tiled = tf.tile( transfer_weights, [ batch_size, 1, 1, 1, 1], name =\"tranf_weig_tiled\" )\n",
    "tranf_weig_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_caps_reshape = tf.reshape( selected_capusles, \n",
    "                              shape = [batch_size, sel_cap_dim, 1, vector_dim, 1],\n",
    "                              name = \"pri_caps_reshape\")\n",
    "sel_caps_tiled = tf.tile( sel_caps_reshape,\n",
    "                         [1, 1, output_labels, 1, 1],\n",
    "                         name = \"pri_caps_tiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'raw_predictions:0' shape=(?, 512, 2, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_caps_pred_vect = tf.matmul( tranf_weig_tiled, sel_caps_tiled,\n",
    "                              name = \"raw_predictions\")\n",
    "all_caps_pred_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-9c31ae7ee038>:8: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "# dynamic routing round-1\n",
    "b = tf.zeros( shape = [1, sel_cap_dim, output_labels, 1, 1], \n",
    "             dtype = tf.float32,\n",
    "             name = \"b\")\n",
    "\n",
    "coup_coeff = tf.nn.softmax( b, \n",
    "                           dim = 2,\n",
    "                           name = \"coup_coeff\")\n",
    "\n",
    "weighted_all_cap_pred = tf.multiply( coup_coeff, all_caps_pred_vect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weighted_all_cap_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-641e5fa8c448>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#sum over all 1152 capsules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m weighted_pred_vec_r1 = tf.reduce_sum( weighted_all_cap_pred, \n\u001b[0m\u001b[0;32m      3\u001b[0m                              \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                              \u001b[0mkeepdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              name = \"weighted_pred_vec_r1\")\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weighted_all_cap_pred' is not defined"
     ]
    }
   ],
   "source": [
    "#sum over all 1152 capsules\n",
    "weighted_pred_vec_r1 = tf.reduce_sum( weighted_all_cap_pred, \n",
    "                             axis = 1, \n",
    "                             keepdims = True,\n",
    "                             name = \"weighted_pred_vec_r1\")\n",
    "\n",
    "pred_vector_r1 = squash(weighted_pred_vec_r1)\n",
    "\n",
    "pred_vector_r1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"agrement:0\", shape=(?, 512, 2, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#agreements\n",
    "pred_vect_r1_tile = tf.tile( pred_vector_r1,\n",
    "                            [ 1, sel_cap_dim, 1, 1, 1],\n",
    "                            name = \"r1_tiled\")\n",
    "agrements = tf.matmul( all_caps_pred_vect, pred_vect_r1_tile ,\n",
    "                     transpose_a = True,\n",
    "                     name = 'agrement')\n",
    "print(agrements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sqrt_3:0\", shape=(?, 1, 2, 1), dtype=float32)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64)\n",
      "Tensor(\"Reshape_4:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# round - 2\n",
    "\n",
    "b = b + agrements\n",
    "coup_coeff_r2 = tf.nn.softmax( b, dim = 2)\n",
    "weighted_all_pred_vect_r2 = tf.multiply( coup_coeff_r2, all_caps_pred_vect)\n",
    "weighted_pred_vect_r2 = tf.reduce_sum( weighted_all_pred_vect_r2, axis = 1, keep_dims = True)\n",
    "pred_vect_r2 = squash(weighted_pred_vect_r2)\n",
    "\n",
    "\n",
    "pred_vect_r2\n",
    "\n",
    "\n",
    "predicted_vector = pred_vect_r2\n",
    "\n",
    "\n",
    "sum_squares = tf.reduce_sum( tf.square(predicted_vector), axis =-2, keep_dims = False, name = \"sum_squares\" )\n",
    "safe_norm1 = tf.sqrt( sum_squares + 1e-7)\n",
    "print(safe_norm1)\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "pred_prob = tf.reshape( safe_norm1, shape = [batch_size, 2])\n",
    "pred_labels = tf.argmax( pred_prob, axis = 1)\n",
    "print(pred_labels)\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "# loss\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lamda = 0.5\n",
    "\n",
    "present_error_raw = tf.square( tf.maximum(0., m_plus - safe_norm1))\n",
    "present_error = tf.reshape( present_error_raw, shape = [-1, 2])\n",
    "print(present_error)\n",
    "\n",
    "absent_error_raw = tf.square( tf.maximum(0., safe_norm1 - m_minus))\n",
    "absent_error = tf.reshape( absent_error_raw, shape = [-1, 2])\n",
    "print(absent_error)\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "#T = tf.one_hot( y, depth = output_labels , name = \"T\")\n",
    "T = y\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "L = tf.add( T * present_error , (lamda * ((1. - T) * absent_error)), name = \"L\" )\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "margin_loss = tf.reduce_mean( tf.reduce_sum(L, axis = 1), name =\"margin_loss\" )\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_step = optimizer.minimize( margin_loss , name=\"train_step\")\n",
    "\n",
    "\n",
    "# correct_predictions = tf.equal( y, pred_labels , name=\"correct\")\n",
    "# accuracy = tf.reduce_mean( tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_eer(scores_true, scores_false):\n",
    "    \n",
    "    \"\"\" Calculate EER\n",
    "        Args:\n",
    "            scores_true: A score list of positive samples\n",
    "            scores_false: A score list of negative samples\n",
    "        Return:\n",
    "            (EER, threshold)\n",
    "        Note:\n",
    "            Here, the threshold is set, and if the score is higher than or equal to the threshold,\n",
    "            the decision is passed, and the decision is rejected as below.\n",
    "    \"\"\"\n",
    "    min1 = min(scores_true)\n",
    "    min2 = min(scores_false)\n",
    "    low = min(min1, min2)\n",
    "    max1 = max(scores_true)\n",
    "    max2 = max(scores_false)\n",
    "    high = max(max1, max2)\n",
    "    FAR = -55\n",
    "    FRR = -55\n",
    "    mid = -100\n",
    "    # Bisection find threshold\n",
    "    while True:\n",
    "        bef_FAR = FAR \n",
    "        bef_FRR = FRR\n",
    "        bef_mid = mid\n",
    "        mid = (high + low) / 2\n",
    "        FRR = sum([1 for s in scores_true if s < mid]) / len(scores_true)\n",
    "        FAR = sum([1 for s in scores_false if s >= mid]) / len(scores_false)\n",
    "        #print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "\n",
    "        if abs(FRR - FAR) < 1e-7:\n",
    "            print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "            break\n",
    "\n",
    "        if FRR < FAR:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "            \n",
    "        if bef_FAR == FAR :\n",
    "            if bef_FRR == FRR :\n",
    "                if bef_mid == mid :\n",
    "                    print(\"FRR  \",FRR,\" FAR   \",FAR,\"   mid   \",mid)\n",
    "                    break\n",
    "\n",
    "    EER  =  FRR\n",
    "    return EER, (high + low) / 2\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "def get_EER(test_path, index, sp_path ):\n",
    "    scores = []\n",
    "    development_labels = []\n",
    "    probabilities = []\n",
    "\n",
    "    #test_path = \"C:\\\\Users\\\\project1\\\\Desktop\\\\Siva\\\\HT_IFCC_hemlata\\\\CNN_input_testing_dev\"\n",
    "    indexs = (len(list(os.listdir(test_path))))//2\n",
    "    \n",
    "    for folders in range(0, indexs):\n",
    "        features = np.load(os.path.join(test_path, \"features\"+str(folders)+\".npy\"))\n",
    "        labels = np.load(os.path.join(test_path, \"labels\"+str(folders)+\".npy\"))\n",
    "        patches = labels.shape[0]\n",
    "        patch_prob = session.run(pred_prob, feed_dict = {x:features})\n",
    "        final_prob = np.zeros([2])\n",
    "        \n",
    "        for i in range(patches):\n",
    "            if(patch_prob[i][0] == 0):\n",
    "                patch_prob[i][0] = 1e-25\n",
    "            if(patch_prob[i][1] == 0):\n",
    "                patch_prob[i][1] = 1e-25\n",
    "                \n",
    "            final_prob[0] = final_prob[0] + np.log(patch_prob[i][0])\n",
    "            final_prob[1] = final_prob[1] + np.log(patch_prob[i][1])\n",
    "\n",
    "        final_prob = final_prob / patches\n",
    "        score = (final_prob[0]) - (final_prob[1])\n",
    "        audio_label = labels[0]\n",
    "\n",
    "        scores.append(score)\n",
    "        probabilities.append( np.mean(patch_prob, axis=0) )\n",
    "        development_labels.append( audio_label )\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    development_labels = np.array(development_labels)\n",
    "    probabilities = np.array(probabilities)\n",
    "\n",
    "    scores_geniue = []\n",
    "    scores_spoof = []\n",
    "    prob_genuine = []\n",
    "    prob_spoof = []\n",
    "\n",
    "    for i in range(development_labels.shape[0]):\n",
    "        if development_labels[i][0] == 1 :\n",
    "            scores_geniue.append(scores[i])\n",
    "            prob_genuine.append(probabilities[i])\n",
    "        elif development_labels[i][1] == 1:\n",
    "            scores_spoof.append(scores[i])\n",
    "            prob_spoof.append(probabilities[i])\n",
    "\n",
    "    scores_geniue = np.array(scores_geniue)\n",
    "    scores_spoof = np.array(scores_spoof)\n",
    "    prob_genuine = np.array(prob_genuine)\n",
    "    prob_spoof = np.array(prob_spoof)\n",
    "    \n",
    "    a,b = cal_eer(scores_geniue, scores_spoof)\n",
    "    \n",
    "    score_path = os.path.join(sp_path, \"scores\")\n",
    "    prob_path = os.path.join(sp_path, \"probabilities\")\n",
    "    \n",
    "    if not os.path.exists(score_path):\n",
    "        os.makedirs(score_path)\n",
    "        \n",
    "    if not os.path.exists(prob_path):\n",
    "        os.makedirs(prob_path)\n",
    "        \n",
    "    prob_file = \"probabilities_\"+str(index)\n",
    "    sc_file = \"scores_\"+str(index)\n",
    "    savemat(os.path.join(score_path, sc_file), { 'genuine':scores_geniue, 'spoof':scores_spoof, 'eer' : a*100 })\n",
    "    savemat(os.path.join(prob_path, prob_file), { 'genuine':prob_genuine, 'spoof':prob_spoof })\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing tensors using sessoion\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=None)\n",
    "features_path = \"/home/speechlab/ASV/siva/IFCC/overlap_data_100_50\"\n",
    "development_path = \"/home/speechlab/ASV/siva/IFCC/dev_overlap_data_100_50\"\n",
    "#evaluation_path = \"E:\\\\Hemlata_CSL\\\\MFCC\\\\CNN_input_testing_eval\"\n",
    "model_path = \"/home/speechlab/ASV/siva/IFCC/CapsuleNet/Models/\"\n",
    "    \n",
    "dev_sp_path =\"/home/speechlab/ASV/siva/IFCC/CapsuleNet/dev\"\n",
    "#eva_sp_path = \"E:\\\\Hemlata_CSL\\\\MFCC\\\\4_conv\\\\eval\""
   ]
  },
  {